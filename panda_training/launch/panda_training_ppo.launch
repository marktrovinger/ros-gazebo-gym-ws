<!--
This launch can be used to train a Soft Actor-Critic (SAC) algorithm on the panda task environments found in the
ros-gazebo-gym package. The training parameters can be set in the ros-gazebo-gym-examples/config/panda_example_training_params.yaml 

Control arguments:
    - control_type: The control type used for controlling the panda robot (Options: trajectory, position, effort, end_effector).
    - environment_type: The panda task environment (Options: Reach, PickAndPlace, Slide, Push).
-->
<launch>
    <!--Control arguments-->
    <!--    The control type used for controlling the panda robot (Options: trajectory, position, effort, end_effector)-->
    <arg name="control_type" default="effort"/>

    <!--Task environment arguments-->
    <!--    The panda task environment.
        NOTE: Options: Reach, PickAndPlace, Slide, Push
    -->
    <arg name="environment_type" default="pick_and_place"/>
    <!--    Whether to use positive reward or not.-->
    <arg name="positive_reward" default="false"/>

    <!--Retrieve ros_gazebo_gym panda environment training parameters-->
    <include file="$(find panda_training)/launch/load_panda_example_training_params.launch.xml"/>

    <!--Launch the training system-->
    <node pkg="panda_training" name="panda_training_ppo" type="start_panda_training_ppo.py" output="screen">
        <param name="control_type" value="$(arg control_type)"/>
        <param name="positive_reward" value="$(arg positive_reward)"/>
        <param name="environment_type" value="$(arg environment_type)"/>
    </node>
</launch>